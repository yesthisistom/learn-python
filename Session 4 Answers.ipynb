{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "path = 'http://text.npr.org'\n",
    "r = requests.get(path)\n",
    "\n",
    "text_to_process = r.text\n",
    "\n",
    "link_queue = set()\n",
    "while text_to_process.find('href=\"') >= 0:\n",
    "    text_to_process = text_to_process[text_to_process.find('href=\"') + 6:]\n",
    "    link = text_to_process[:text_to_process.find('\"')]\n",
    "    ## Add http here in part 2\n",
    "    \n",
    "    link_queue.add(link)\n",
    "    text_to_process = text_to_process[text_to_process.find('\"') + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "path = 'http://text.npr.org'\n",
    "r = requests.get(path)\n",
    "\n",
    "text_to_process = r.text\n",
    "\n",
    "link_queue = set()\n",
    "while text_to_process.find('href=\"') >= 0:\n",
    "    text_to_process = text_to_process[text_to_process.find('href=\"') + 6:]\n",
    "    link = text_to_process[:text_to_process.find('\"')]\n",
    "    if not link.startswith('http'):\n",
    "        link = path + link\n",
    "    link_queue.add(link)\n",
    "    text_to_process = text_to_process[text_to_process.find('\"') + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_to_return = set()\n",
    "\n",
    "for link in link_queue:\n",
    "    if 'npr.org' in link:\n",
    "        if  'sid=' in link.lower() or 'tid=' in link.lower():\n",
    "            queue_to_return.add(link)\n",
    "        \n",
    "queue_to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(html_text):\n",
    "    link_queue = set()\n",
    "    while html_text.find('href=\"') >= 0:\n",
    "        html_text = html_text[html_text.find('href=\"') + 6:]\n",
    "        link = html_text[:html_text.find('\"')]\n",
    "        \n",
    "        if not link.startswith('http'):\n",
    "            link = path + link\n",
    "        \n",
    "        if 'npr.org' in link:\n",
    "            if  'sid=' in link.lower() or 'tid=' in link.lower():\n",
    "                link_queue.add(link)\n",
    "        \n",
    "        html_text = html_text[html_text.find('\"') + 1:]\n",
    "        \n",
    "    return link_queue\n",
    "\n",
    "link_queue = get_links(r.text)\n",
    "link_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_html = requests.get(\"http://text.npr.org/s.php?sId=575392333\").text\n",
    "article_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paragraphs = []\n",
    "while article_html.find('<p>') >= 0:\n",
    "    article_html = article_html[article_html.find('<p>') + 3:]\n",
    "    paragraph = article_html[:article_html.find('</p>')]\n",
    "    \n",
    "    print(paragraph)\n",
    "    paragraphs.append(paragraph)\n",
    "    \n",
    "    article_html = article_html[article_html.find('</p>') + 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_paragraphs = []\n",
    "for paragraph in paragraphs:\n",
    "    new_paragraph = \"\"\n",
    "    \n",
    "    tag = False\n",
    "    for char in paragraph:\n",
    "        \n",
    "        if char == \"<\":\n",
    "            tag = True\n",
    "            \n",
    "        if not tag:\n",
    "            new_paragraph += char\n",
    "            \n",
    "        if char == \">\":\n",
    "            tag = False\n",
    "        \n",
    "        \n",
    "    if len(new_paragraph.strip()) > 0:\n",
    "        cleaned_paragraphs.append(new_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for paragraph in cleaned_paragraphs:\n",
    "    print(paragraph + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_text(article_html):\n",
    "    paragraphs = []\n",
    "    while article_html.find('<p>') >= 0:\n",
    "        article_html = article_html[article_html.find('<p>') + 3:]\n",
    "        paragraph = article_html[:article_html.find('</p>')]\n",
    "\n",
    "        new_paragraph = \"\"\n",
    "    \n",
    "        tag = False\n",
    "        for char in paragraph:\n",
    "\n",
    "            if char == \"<\":\n",
    "                tag = True\n",
    "            if not tag:\n",
    "                new_paragraph += char\n",
    "            if char == \">\":\n",
    "                tag = False\n",
    "\n",
    "        if len(new_paragraph.strip()) > 0:\n",
    "            paragraphs.append(new_paragraph)\n",
    "\n",
    "        article_html = article_html[article_html.find('</p>') + 4:]\n",
    "        \n",
    "    return \"\\n\\n\".join(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_html = requests.get(\"http://text.npr.org/s.php?sId=575392333\").text\n",
    "\n",
    "print(parse_text(article_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id(url):\n",
    "    url = url[url.lower().find('sid=') + 4:]\n",
    "    if '&' in url:\n",
    "        url = url[:url.find('&')]\n",
    "        \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "starting_url = 'http://text.npr.org'\n",
    "folder_out   = 'data/scraper_test/'\n",
    "\n",
    "if not os.path.exists(folder_out):\n",
    "    os.makedirs(folder_out)\n",
    "\n",
    "links_visited = set()\n",
    "links_queue   = get_links(requests.get(starting_url).text)\n",
    "\n",
    "while len(links_queue) > 0:\n",
    "    \n",
    "    link = links_queue.pop()\n",
    "    links_visited.add(link)\n",
    "    \n",
    "    html = requests.get(link).text\n",
    "    \n",
    "    urls = get_links(html)\n",
    "    for url in urls:\n",
    "        if not url in links_visited:\n",
    "            links_queue.add(url)\n",
    "            \n",
    "    if 'sid=' in link.lower():\n",
    "        text = parse_text(html)\n",
    "        article_id = get_id(link)\n",
    "        \n",
    "        with open(folder_out + article_id + \".txt\", \"w\") as ft_hdl:\n",
    "            ft_hdl.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
