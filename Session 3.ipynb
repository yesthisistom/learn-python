{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Session 3 - Reading/Writing Data</center>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<b>\n",
    "\n",
    "* <a href=\"#Reading Text\">Reading Text</a>\n",
    "* <a href=\"#CSV\">CSV</a>\n",
    "* [Exercise 1](#Exercise 1)\n",
    "* [Finding Multiple Files](#Glob)\n",
    "* [Exercise 2](#Exercise2)\n",
    "* <a href=\"#Writing\">Writing</a>\n",
    "* <a href=\"#Requests\">Requests</a>\n",
    "* [Exercise 3](#Exercise3)\n",
    "\n",
    "</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Reading Text\"></a>\n",
    "<hr>\n",
    "# Reading Text\n",
    "\n",
    "Python comes with a built-in function 'open()', which takes the path (relative or absolute) to the file you're interested in opening.  \n",
    "\n",
    "    # Example \n",
    "    file = 'data/text_file.txt'\n",
    "    file_hdl = open(file)\n",
    "    text = file_hdl.read()\n",
    "    \n",
    "    file_hdl.close() # Don't forget to close that file handle!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'data/text_file.txt'\n",
    "file_hdl = open(file)\n",
    "text = file_hdl.read()\n",
    "\n",
    "file_hdl.close()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has an more consise way to do this that doesn't require the developer to remember to close the file handle. \n",
    "\n",
    "    with open(file) as file_hdl:\n",
    "        text = file_hdl.read()\n",
    "        \n",
    "When the indented block ends, python closes the file handle automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file) as file_hdl:\n",
    "    text_v2 = file_hdl.read()\n",
    "    \n",
    "print(text_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CSV\"></a>\n",
    "<hr>\n",
    "# CSV\n",
    "\n",
    "A CSV (Comma Seperated Value) file is a lot like an excel workbook (and in fact can be read by excel).  Python has a library intended for reading and writing CSV files, and it relies on the built in open function. \n",
    "\n",
    "    import csv  # You only need to run this once per project\n",
    "    \n",
    "    csv_path = \"data/quiz_questions.csv\"\n",
    "    \n",
    "    with open(csv_path) as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        for row in csv_reader:\n",
    "             print(row)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv  # You only need to run this once per project\n",
    "    \n",
    "csv_path = \"data/quiz_questions.csv\"\n",
    "    \n",
    "with open(csv_path) as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for row in csv_reader:\n",
    "         print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it pulls the header as the first row - Having a header be able to map to each row would be really useful.  The CSV library has a dictionary reader that reads each line in as a single dictionary, mapping the column header to the value in the row.  \n",
    "\n",
    "    with open(csv_path) as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "             print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(csv_path) as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "    for row in csv_reader:\n",
    "         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise 1\"></a>\n",
    "\n",
    "# Exercise 1\n",
    "\n",
    "Take the dictionary we just read in using CSV, and ask the user for their answer.  If that answer is not mapped to the value 'correct' in the dictionary, print the hint and ask again. \n",
    "\n",
    "Look at the dictionary keys if you're not sure exactly where to begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id=\"Glob\"></a>\n",
    "# Finding multiples files\n",
    "\n",
    "If you have a folder with a lot of files, and you're looking for a generic pattern or extension, using a library like glob can make you life a lot easier. \n",
    "\n",
    "In the 'data/articles' folder there is a bunch of .txt files, each containing an article pulled from NPR.  There's also a .csv file containing additional information about the articles.  If we wanted to read ALL of the txt files, we can get a list of them in one fell swoop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path = \"data/articles\"\n",
    "txt_list = glob.glob(path + \"/*.txt\")\n",
    "\n",
    "print(len(txt_list))\n",
    "print(txt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise2\"></a>\n",
    "\n",
    "# Exercise 2\n",
    "\n",
    "Look at the file '/data/articles/article_log.csv', and get a sense of what it contains.  Note that the id maps to a filename (ie ID 569893288 maps to 569893288.txt)\n",
    "\n",
    "Write some code that reads in each line in the article_log.csv as a dictionary, and add each dictionary to a larger dictionary, mapping the ID of the article to that dictionary for that line. See below for the results of reading in a single line. \n",
    "\n",
    "\n",
    "    {'569893288': {('ID', '569893288'),\n",
    "               ('Date', '2017-12-14'),\n",
    "               ('Title', \"NPR's Favorite TV Shows Of 2017\"),\n",
    "               ('Link',\n",
    "               'https://www.npr.org/sections/monkeysee/2017/12/14/569893288/nprs-favorite-tv-shows-of-2017')])}\n",
    "               \n",
    "Make sure to give the larger dictionary the variable name 'data_dict', as we'll use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Loop over all the article txt files you found.  For each file:\n",
    "\n",
    "1. Get the ID from the filename\n",
    "2. Read in the content\n",
    "3. Get the following and add them to the dictionary for each article:\n",
    "    3. Get the number of characters for each article\n",
    "    4. Get the number of sentences for each article\n",
    "    5. Get the number of paragraphs for each article\n",
    "    \n",
    "Potentially useful functions:\n",
    "\n",
    "If you have a string as a variable, you can replace text in it, using .replace()\n",
    "    \n",
    "    For example, if you have the variable \n",
    "    \n",
    "    test = \"textfile.txt\"\n",
    "    test = test.replace(\".txt\", \"\")\n",
    "    # test now equals 'textfile'\n",
    "    \n",
    "    test2 = \"Sentence one. Sentence 2\"\n",
    "    split_test2 = test2.split(\".\")\n",
    "    # split_test2 is now a list containing the string \"Setence one\" and \" Sentence 2\"\n",
    "    \n",
    "In a string variaible, a newline can be found using the '\\n' character.  In many news articles, a paragraph can be indentified by two newline characters in a row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Writing\"></a>\n",
    "\n",
    "<hr>\n",
    "# Writing to File\n",
    "\n",
    "The open function can take more than just a filename. The second argument, which is optional, defaults to reading, but can have a number of other options.  You can tell it to append to a file, write to a file, write to a file ONLY if the file doesn't already exist, and more. \n",
    "\n",
    "In the case of writing to a file, we pass the 'w' argument.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write the CSV file with the adjusted dictionaries, we'll use the the DictWriter from the csv library, and a 'w' in our open call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_out = \"data/articles/article_log_improved.csv\"\n",
    "with open(file_out, 'w') as file_out_hdl:\n",
    "    # This line is a bit confusing. \n",
    "    # We need to tell the writer WHERE to write, but also what the headers are. \n",
    "    # To get the headers, we need to get ANY single line dictionary, and get the keys for it\n",
    "    writer = csv.DictWriter(file_out_hdl, next (iter (data_dict.values())).keys())\n",
    "    \n",
    "    writer.writeheader()\n",
    "\n",
    "    for key,value in data_dict.items():\n",
    "        writer.writerow(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id=\"Writing\"></a>\n",
    "\n",
    "# Requests\n",
    "\n",
    "One final way to get data is the requests library.  We can use it to get all the contant of a URL, whether that be HTML, JSON, or some other internet format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "path = 'http://text.npr.org/s.php?sId=572945894'\n",
    "r = requests.get(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://text.npr.org/s.php?sId=572945894'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_json = requests.get(\"https://api.weather.gov/points/38.8048,-77.0469\").json()\n",
    "forecast_url = weather_json[\"properties\"][\"forecast\"]\n",
    "forecast_json = requests.get(forecast_url).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight: Mostly Clear and 38F\n",
      "Wednesday: Mostly Sunny and 47F\n",
      "Wednesday Night: Partly Cloudy and 30F\n",
      "Thursday: Sunny and 43F\n",
      "Thursday Night: Mostly Clear and 28F\n",
      "Friday: Sunny and 50F\n",
      "Friday Night: Mostly Clear and 35F\n",
      "Saturday: Slight Chance Light Rain and 56F\n",
      "Saturday Night: Chance Light Rain and 47F\n",
      "Sunday: Light Rain Likely and 57F\n",
      "Sunday Night: Chance Rain And Snow Showers and 37F\n",
      "Monday: Chance Rain And Snow Showers and 47F\n",
      "Monday Night: Slight Chance Rain Showers then Partly Cloudy and 27F\n",
      "Tuesday: Sunny and 42F\n"
     ]
    }
   ],
   "source": [
    "for period in forecast_json[\"properties\"][\"periods\"]:\n",
    "    print(period[\"name\"] + \":\",\n",
    "          period[\"shortForecast\"], \"and\",\n",
    "          str(period[\"temperature\"]) + \n",
    "          period[\"temperatureUnit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise3\"></a>\n",
    "\n",
    "# Exercise 3\n",
    "\n",
    "Use string functions to print ONLY the text between the paragraph tags in the html. \n",
    "\n",
    "To find the starting index of a character sequence in a string, use the .find() function. \n",
    "\n",
    "    test_str = \"The quick brown fox jumped over the lazy dog\"\n",
    "    fox_idx = test_str.find(\"fox\") #now fox_idx will equal 16\n",
    "    \n",
    "    print(test_str[fox_idx:]) ## Will print 'fox jumped over the lazy dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
